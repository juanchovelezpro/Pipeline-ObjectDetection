{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfeWYiT6aNDa"
   },
   "source": [
    "# **Proyecto de grado**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAGVzME9DIPn"
   },
   "source": [
    "## *Aplicación móvil en Android con OCR para la lectura del consumo en medidores eléctricos de clientes residenciales en Santiago de Cali.*\n",
    "\n",
    "### **Integrantes**\n",
    "\n",
    "\n",
    "*   Daniel Alejandro Cerquera Castro\n",
    "*   Brayan Starlin Garcés Portillo\n",
    "*   Juan Camilo Vélez Olaya\n",
    "\n",
    "### **Tutor**\n",
    "\n",
    "*   Carlos Alberto Arce Lopera\n",
    "\n",
    "En este Colab o Notebook, se explican cada uno de los pasos para la creación de un modelo de machine learning que detecte y reconozca los digitos que muestran el consumo de un medidor eléctrico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGr1XCdZMVGL"
   },
   "source": [
    "# **Requerimientos**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ek8XTQ0lv5PN"
   },
   "source": [
    "1.   Un dataset con el que se entrenará el modelo. En este proyecto se utiliza un dataset de 2300 imágenes.\n",
    "2.   El etiquetado del dataset.\n",
    "3.   Configuración del pipeline para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLnOOi3nu42k"
   },
   "source": [
    "# **Procedimiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzdaHOIDvFo0"
   },
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgQ-y_rqnZV1"
   },
   "outputs": [],
   "source": [
    "# Verificamos versiones de Python y TensorFlow (Python 3.7.10 y TensorFlow 2.4.1)\n",
    "!python3 --version\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_bnWov08T-9"
   },
   "outputs": [],
   "source": [
    "# Se verifica la TPU.\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Si3sOwi7e06"
   },
   "outputs": [],
   "source": [
    "# Primero montamos Google Drive para crear nuestras carpetas y archivos necesarios para el pipeline.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dW4lm8371iZ"
   },
   "outputs": [],
   "source": [
    "# Clonamos el repo de TensorFlow Models para obtener el Object Detection API\n",
    "\n",
    "%cd '/content/gdrive/My Drive/TensorFlow'\n",
    "\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "\n",
    "# Se usa una version anterior por compatibilidad.\n",
    "%cd '/content/gdrive/MyDrive/TensorFlow/models'\n",
    "!git checkout -f c3d53565f3b5964e7ab46cb9a23689ceacc8823a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "So0uPn6C8j-Z"
   },
   "outputs": [],
   "source": [
    "# Se instalan algunas librerias necesarias para el preprocesamiento del dataset.\n",
    "\n",
    "!apt-get install protobuf-compiler python-lxml python-pil\n",
    "!pip install Cython pandas tf-slim lvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BI9kNtN9Hca"
   },
   "outputs": [],
   "source": [
    "# Se compilan las librerias de Protobuf\n",
    "\n",
    "%cd '/content/gdrive/My Drive/TensorFlow/models/research/'\n",
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEAg3ksA9Pih"
   },
   "outputs": [],
   "source": [
    "# Se configura la variable de entorno.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ['PYTHONPATH']+=\":/content/gdrive/My Drive/TensorFlow/models\"\n",
    "sys.path.append(\"/content/gdrive/My Drive/TensorFlow/models/research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UT9-acjE9d2K"
   },
   "outputs": [],
   "source": [
    "# Se hace el build y la instalacion del object detection api.\n",
    "\n",
    "!python setup.py build\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7M5qUba89u3S"
   },
   "outputs": [],
   "source": [
    "# Se comprueba que todo haya sido instalado correctamente\n",
    "\n",
    "%cd '/content/gdrive/My Drive/TensorFlow/models/research/object_detection/builders/'\n",
    "!python model_builder_tf2_test.py\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxQvJ6bqvRX0"
   },
   "source": [
    "## **Pre procesamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5C5-PCp-elV"
   },
   "outputs": [],
   "source": [
    "# Se generan los .record para realizar el entrenamiento y validacion. (El dataset ya se debe encontrar etiquetado)\n",
    "\n",
    "%cd '/content/gdrive/My Drive/TensorFlow/scripts/preprocessing'\n",
    "\n",
    "# Se genera el train.record para entrenar y el test.record para validar.\n",
    "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/train' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/train.record'\n",
    "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/test' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/test.record'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSQzwjKCvc2P"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JISAAfK-inS"
   },
   "outputs": [],
   "source": [
    "# Iniciamos TensorBoard para visualizar algunas metricas.\n",
    "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
    "\n",
    "# Para evauluar el modelo.\n",
    "#!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config --checkpoint_dir=models/my_ssd_resnet50_v1_fpn\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir=models/my_ssd_resnet50_v1_fpn/eval\n",
    "\n",
    "# Para hacer tracking mediante el entrenamiento.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=models/my_ssd_resnet50_v1_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_hgJrWJuC_O"
   },
   "outputs": [],
   "source": [
    "# Para checkear tiempo restante en el colab.\n",
    "\n",
    "import time,psutil\n",
    "uptime=time.time()-psutil.boot_time()\n",
    "remaintime=(12*60*60)-uptime\n",
    "print(remaintime/(60*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFLP5SUS-vYa"
   },
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
    "\n",
    "!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config --use_tpu=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCvMNpFCvjJe"
   },
   "source": [
    "## **Exportar el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDSirOAQ-0sy"
   },
   "outputs": [],
   "source": [
    "# Exportar el modelo entrenado.\n",
    "\n",
    "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir ./models/my_ssd_resnet50_v1_fpn/ --output_directory ./exported-models/my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwyDMwt-vpZ0"
   },
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nz2jiOgJ4mUK"
   },
   "outputs": [],
   "source": [
    "# Testear el modelo\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_SAVED_MODEL=\"/content/gdrive/My Drive/TensorFlow/workspace/training_demo/exported-models/my_model/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "\n",
    "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sX--5tHy4-S1"
   },
   "outputs": [],
   "source": [
    "# Se obtienen los labels con los que se etiquetó el modelo.\n",
    "\n",
    "category_index=label_map_util.create_category_index_from_labelmap(\"/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt\",use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UURD_H_c5grh"
   },
   "outputs": [],
   "source": [
    "# Cargamos algunas imagenes para comprobar su funcionamiento.\n",
    "img=['/content/img1.jpg','/content/img2.jpg']\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNLxnQNa54d_"
   },
   "outputs": [],
   "source": [
    "# Corremos la inferencia del modelo\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "for image_path in img:\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "    image_np=load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor=tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor=input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections=detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections=int(detections.pop('num_detections'))\n",
    "    detections={key:value[0,:num_detections].numpy()\n",
    "                   for key,value in detections.items()}\n",
    "    detections['num_detections']=num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes']=detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections=image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=10,     #max number of bounding boxes in the image\n",
    "          min_score_thresh=.5,      #min prediction threshold\n",
    "          agnostic_mode=False)\n",
    "    %matplotlib inline\n",
    "    plt.figure()\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    print('Done')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "KfeWYiT6aNDa",
    "NGr1XCdZMVGL",
    "ZzdaHOIDvFo0",
    "wxQvJ6bqvRX0",
    "LSQzwjKCvc2P",
    "oCvMNpFCvjJe",
    "OwyDMwt-vpZ0"
   ],
   "machine_shape": "hm",
   "name": "PDG Electric Meter Reader.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}