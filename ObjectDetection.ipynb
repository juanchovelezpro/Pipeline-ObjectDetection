{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PDG Electric Meter Reader.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KfeWYiT6aNDa",
        "NGr1XCdZMVGL",
        "ZzdaHOIDvFo0",
        "wxQvJ6bqvRX0",
        "LSQzwjKCvc2P",
        "oCvMNpFCvjJe",
        "OwyDMwt-vpZ0"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfeWYiT6aNDa"
      },
      "source": [
        "# **Proyecto de grado**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAGVzME9DIPn"
      },
      "source": [
        "## *Aplicación móvil en Android con OCR para la lectura del consumo en medidores eléctricos de clientes residenciales en Santiago de Cali.*\n",
        "\n",
        "### **Integrantes**\n",
        "\n",
        "\n",
        "*   Daniel Alejandro Cerquera Castro\n",
        "*   Brayan Starlin Garcés Portillo\n",
        "*   Juan Camilo Vélez Olaya\n",
        "\n",
        "### **Tutor**\n",
        "\n",
        "*   Carlos Alberto Arce Lopera\n",
        "\n",
        "En este Colab o Notebook, se explican cada uno de los pasos para la creación de un modelo de machine learning que detecte y reconozca los digitos que muestran el consumo de un medidor eléctrico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGr1XCdZMVGL"
      },
      "source": [
        "# **Requerimientos**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek8XTQ0lv5PN"
      },
      "source": [
        "1.   Un dataset con el que se entrenará el modelo. En este proyecto se utiliza un dataset de 2420 imágenes. (1800 training, 500 validation, 120 testing)\n",
        "2.   El etiquetado del dataset. (LabelImg)\n",
        "3.   Configuración del pipeline para entrenar el modelo. (pipeline.config de los modelos de Object Detection API de la TF2 Model Zoo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLnOOi3nu42k"
      },
      "source": [
        "# **Procedimiento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzdaHOIDvFo0"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdTGn1JTFBf6"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgQ-y_rqnZV1"
      },
      "source": [
        "# Verificamos versiones de Python y TensorFlow (Python 3.7.10 y TensorFlow 2.5.0)\n",
        "!python --version\n",
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_bnWov08T-9"
      },
      "source": [
        "# Se verifica la TPU.\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Si3sOwi7e06"
      },
      "source": [
        "# Primero montamos Google Drive para crear nuestras carpetas y archivos necesarios para el pipeline.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dW4lm8371iZ"
      },
      "source": [
        "# Clonamos el repo de TensorFlow Models para obtener el Object Detection API\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow'\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So0uPn6C8j-Z"
      },
      "source": [
        "# Se instalan algunas librerias necesarias para el preprocesamiento del dataset.\n",
        "\n",
        "!apt-get install protobuf-compiler python-lxml python-pil\n",
        "!pip install Cython pandas tf-slim lvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BI9kNtN9Hca"
      },
      "source": [
        "# Se compilan las librerias de Protobuf\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/'\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEAg3ksA9Pih"
      },
      "source": [
        "# Se configura la variable de entorno.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "os.environ['PYTHONPATH']+=\":/content/gdrive/My Drive/TensorFlow/models\"\n",
        "sys.path.append(\"/content/gdrive/My Drive/TensorFlow/models/research\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT9-acjE9d2K"
      },
      "source": [
        "# Se hace el build y la instalacion del object detection api.\n",
        "\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/'\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "\n",
        "!python setup.py build\n",
        "!python setup.py install\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M5qUba89u3S"
      },
      "source": [
        "# Se comprueba que todo haya sido instalado correctamente\n",
        "\n",
        "#%cd '/content/gdrive/My Drive/TensorFlow/models/research/object_detection/builders/'\n",
        "#!python model_builder_tf2_test.py\n",
        "#from object_detection.utils import label_map_util\n",
        "#from object_detection.utils import visualization_utils as viz_utils\n",
        "#print('Done')\n",
        "\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxQvJ6bqvRX0"
      },
      "source": [
        "## **Pre procesamiento**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5C5-PCp-elV"
      },
      "source": [
        "# Se generan los .record para realizar el entrenamiento y validacion. (El dataset ya se debe encontrar etiquetado)\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/scripts/preprocessing'\n",
        "\n",
        "# Se genera el train.record para entrenar y el test.record para validar.\n",
        "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/train' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/train.record'\n",
        "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/test' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/test.record'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSQzwjKCvc2P"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JISAAfK-inS"
      },
      "source": [
        "# Iniciamos TensorBoard para visualizar algunas metricas.\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "\n",
        "# Para evauluar el modelo.\n",
        "#!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config --checkpoint_dir=models/my_ssd_resnet50_v1_fpn\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir=models/my_ssd_resnet50_v1_fpn/eval\n",
        "\n",
        "# Para hacer tracking mediante el entrenamiento.\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=gs://ocrappbucket/models/my_ssd_resnet101_v1_fpn_d/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_hgJrWJuC_O"
      },
      "source": [
        "# Para checkear tiempo restante en el colab.\n",
        "\n",
        "import time,psutil\n",
        "uptime=time.time()-psutil.boot_time()\n",
        "remaintime=(12*60*60)-uptime\n",
        "print(remaintime/(60*60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFLP5SUS-vYa"
      },
      "source": [
        "# Entrenar el modelo\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "\n",
        "!python model_main_tf2.py --model_dir=gs://ocrappbucket/models/my_ssd_resnet101_v1_fpn_d --pipeline_config_path=gs://ocrappbucket/models/my_ssd_resnet101_v1_fpn_d/pipeline.config --use_tpu=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCvMNpFCvjJe"
      },
      "source": [
        "## **Exportar el modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDSirOAQ-0sy"
      },
      "source": [
        "# Exportar el modelo entrenado.\n",
        "#%cd '/content/gdrive/My Drive/TensorFlow/models/research'\n",
        "\n",
        "# Graph for Conversion TFLite\n",
        "#!python object_detection/export_tflite_graph_tf2.py --pipeline_config_path gs://ocrappbucket/models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir gs://ocrappbucket/models/my_ssd_resnet50_v1_fpn/ --output_directory /content/exported\n",
        "\n",
        "# For Inference\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path gs://ocrappbucket/models/my_ssd_resnet101_v1_fpn_d/pipeline.config --trained_checkpoint_dir gs://ocrappbucket/models/my_ssd_resnet101_v1_fpn_d/ --output_directory gs://ocrappbucket/exported-models/my_ssd_resnet101_v1_fpn_d/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwyDMwt-vpZ0"
      },
      "source": [
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obSQpwd6PLaz"
      },
      "source": [
        "# Testing for TFlite\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/detect.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Print input shape and type\n",
        "inputs = interpreter.get_input_details()\n",
        "print('{} input(s):'.format(len(inputs)))\n",
        "for i in range(0, len(inputs)):\n",
        "    print('{} {}'.format(inputs[i]['shape'], inputs[i]['dtype']))\n",
        "\n",
        "# Print output shape and type\n",
        "outputs = interpreter.get_output_details()\n",
        "print('\\n{} output(s):'.format(len(outputs)))\n",
        "for i in range(0, len(outputs)):\n",
        "    print('{} {}'.format(outputs[i]['shape'], outputs[i]['dtype']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz2jiOgJ4mUK"
      },
      "source": [
        "# Testear el modelo\n",
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL='gs://ocrappbucket/exported-models/my_ssd_resnet101_v1_fpn_d/saved_model/'\n",
        "\n",
        "print('Loading model...', end='')\n",
        "\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "infer = detect_fn.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX--5tHy4-S1"
      },
      "source": [
        "# Se obtienen los labels con los que se etiquetó el modelo.\n",
        "\n",
        "category_index=label_map_util.create_category_index_from_labelmap(\"gs://ocrappbucket/annotations/label_map.pbtxt\",use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UURD_H_c5grh"
      },
      "source": [
        "# Cargamos algunas imagenes para comprobar su funcionamiento.\n",
        "img=['/content/img1.jpeg','/content/img2.jpeg','/content/img3.jpeg','/content/img4.jpeg','/content/img5.jpeg','/content/img6.jpeg','/content/img7.jpg']\n",
        "print(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNLxnQNa54d_"
      },
      "source": [
        "# Corremos la inferencia del modelo\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import matplotlib as mat\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "%cd '/content/gdrive/My Drive/'\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "index = 0\n",
        "for image_path in img:\n",
        "    \n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "    image_np=load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor=tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor=input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections=detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections=int(detections.pop('num_detections'))\n",
        "    detections={key:value[0,:num_detections].numpy()\n",
        "                   for key,value in detections.items()}\n",
        "    detections['num_detections']=num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes']=detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections=image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=10,     #max number of bounding boxes in the image\n",
        "          min_score_thresh=.5,      #min prediction threshold\n",
        "          agnostic_mode=False)\n",
        "    %matplotlib inline\n",
        "    mat.pyplot.imsave('inference'+str(index)+'.jpeg',image_np_with_detections)\n",
        "    index = index + 1\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "    plt.show()\n",
        "\n",
        "print(detections['detection_classes'])\n",
        "print(detections['detection_scores'].shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chby2E_v9gOp"
      },
      "source": [
        "## **SavedModel a TensorFlow Lite**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvk2at4vZgYQ"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/exported/saved_model')\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.experimental_new_converter = True\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "output = args.output + '/content/ocr.tflite'\n",
        "with tf.io.gfile.GFile(output, 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmGifkCDGOcp"
      },
      "source": [
        "!tflite_convert --output_file /content/model.tflite --saved_model_dir /content/exported/saved_model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}